{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compound-feeling",
   "metadata": {},
   "source": [
    "# The Machine Leaning Company Fellowship task\n",
    "\n",
    "Problem statement (Multiclass Image Classification)-\n",
    "\n",
    "Train any neural network of your choice on 102 flowers dataset. Prepare an in-depth notebook on the same. Explain each and every step in suitable words. Unique approach will carry more marks.\n",
    "\n",
    "## The data\n",
    "\n",
    "The training data, as provided in the mail, is available in `./oxford-102-flowers/train.txt` file.\n",
    "\n",
    "The cross-validation data, as provided in the mail, is available in `./oxford-102-flowers/valid.txt` file.\n",
    "\n",
    "The testing data, as provided in the mail, is available in `./oxford-102-flowers/train.txt` file.\n",
    "\n",
    "## A brief summary\n",
    "\n",
    "We will be exploring convulation neural networks in this notebook. The networks will consist of some convulation layers, followed by max pooling layers which will be fully connected to an artificial neural network layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-james",
   "metadata": {},
   "source": [
    "## Starting up\n",
    "\n",
    "We start by importing all the necessary modules and making sure that `tensorflow` uses GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "useful-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# using GPU\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-crack",
   "metadata": {},
   "source": [
    "## Reading the text files\n",
    "\n",
    "Next we read the text files and extract the data in a python readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "after-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_for_data(path):\n",
    "    \"\"\"\n",
    "    Reads a text file and returns the data with corresponding image path and label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path of the text file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data : list\n",
    "        Extracted data of the form -\n",
    "        [\n",
    "            ['path/to/image/1', 'label'],\n",
    "            ['path/to/image/2', 'label'],\n",
    "            ['path/to/image/3', 'label']\n",
    "        ]\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        text = f.readlines()\n",
    "        text = [line.replace(\"\\n\", \"\") for line in text]\n",
    "        data = np.array([line.split() for line in text])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-fraction",
   "metadata": {},
   "source": [
    "Now we extract all the data one by one. Here I decided to exchange train and test data as the test data had around 6100 entries whereas the train data had only around 1000 entries. I did try using the train dataset for training but due to the low amount of data points, the model was performing very poorly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-crisis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jpg/image_03860.jpg', '16'],\n",
       "       ['jpg/image_06092.jpg', '13'],\n",
       "       ['jpg/image_02400.jpg', '42'],\n",
       "       ['jpg/image_02852.jpg', '55'],\n",
       "       ['jpg/image_07710.jpg', '96']], dtype='<U19')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = read_file_for_data(\"./oxford-102-flowers/train.txt\")\n",
    "test_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "actual-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jpg/image_04467.jpg', '89'],\n",
       "       ['jpg/image_07129.jpg', '44'],\n",
       "       ['jpg/image_05166.jpg', '4'],\n",
       "       ['jpg/image_07002.jpg', '34'],\n",
       "       ['jpg/image_02007.jpg', '79']], dtype='<U19')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_valid_dataset = read_file_for_data(\"./oxford-102-flowers/valid.txt\")\n",
    "cross_valid_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dated-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['jpg/image_06977.jpg', '34'],\n",
       "       ['jpg/image_00800.jpg', '80'],\n",
       "       ['jpg/image_05038.jpg', '58'],\n",
       "       ['jpg/image_06759.jpg', '0'],\n",
       "       ['jpg/image_01133.jpg', '45']], dtype='<U19')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = read_file_for_data(\"./oxford-102-flowers/test.txt\")\n",
    "train_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-vault",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n",
    "Now we have the data, but not in an ideal format. We would like to have something like this -\n",
    "```py\n",
    "features = [\n",
    "    numpy_image_1,\n",
    "    numpy_image_2\n",
    "    .\n",
    "    .\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    label1,\n",
    "    label2\n",
    "    .\n",
    "    .\n",
    "]\n",
    "```\n",
    "\n",
    "To achieve this, we process the list of dataset obtained above using a function -\n",
    "1. For the images, we will read a single image as a numpy array, resize it, and then will normalise the features.\n",
    "2. For the labels, we will convert the `str` labels to `int` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "honey-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_and_labels(dataset):\n",
    "    \"\"\"\n",
    "    Generates features and labels from a list of data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        Of the form -\n",
    "        [\n",
    "            ['path/to/image/1', 'label'],\n",
    "            ['path/to/image/2', 'label'],\n",
    "            ['path/to/image/3', 'label']\n",
    "        ]\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        features : np.ndarray\n",
    "            Of the form -\n",
    "                [\n",
    "                    numpy_image_1,\n",
    "                    numpy_image_2\n",
    "                    .\n",
    "                    .\n",
    "                ]\n",
    "        labels : np.ndarray\n",
    "            Of the form -\n",
    "                [\n",
    "                    label1,\n",
    "                    label2\n",
    "                    .\n",
    "                    .\n",
    "                ]\n",
    "         \n",
    "    \"\"\"\n",
    "    \n",
    "    # extract all the image paths\n",
    "    images = np.array(dataset[:, 0])\n",
    "    features = []\n",
    "\n",
    "    # loop through the image paths\n",
    "    for image in images:\n",
    "        \n",
    "        # read an image as a numpy array\n",
    "        img = cv2.imread(f\"./oxford-102-flowers/{image}\")\n",
    "        #resize the image into 64X64\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        # append the image\n",
    "        features.append(img)\n",
    "\n",
    "    # convert features to a numpy array\n",
    "    features = np.array(features)\n",
    "    # normalise features\n",
    "    features = features / 255.0\n",
    "    \n",
    "    # taking labels from the dataset\n",
    "    labels = np.array([int(x) for x in dataset[:, 1]])\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-nightlife",
   "metadata": {},
   "source": [
    "Now we are ready to generate the features and the corresponding labels. For the training dataset we do this in parts, as my laptop was not able to process more than 1000 images in a single loop or in a nested loop.\n",
    "\n",
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "resident-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = generate_features_and_labels(train_dataset[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efficient-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[1000:2000])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "future-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[2000:3000])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incident-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[3000:4000])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "corrected-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[4000:5000])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "single-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[5000:6000])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hollywood-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = generate_features_and_labels(train_dataset[6000:])\n",
    "x_train = np.concatenate((x_train, x))\n",
    "y_train = np.concatenate((y_train, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-tourist",
   "metadata": {},
   "source": [
    "### Visualising the training dataset\n",
    "\n",
    "One can see that the training dataset is not uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overall-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train, bins=[x for x in range(0, 103)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-bryan",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dental-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-adobe",
   "metadata": {},
   "source": [
    "### Visualising testing dataset\n",
    "\n",
    "The testing dataset is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "grave-trigger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test, bins=[x for x in range(0, 103)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-juice",
   "metadata": {},
   "source": [
    "### Cross-validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developing-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cross_valid, y_cross_valid = generate_features_and_labels(cross_valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-broad",
   "metadata": {},
   "source": [
    "### Visualising Cross-validation dataset\n",
    "\n",
    "The cross-validation dataset is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "exempt-inspiration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAALtklEQVR4nO3db4hl9X3H8fenTv6tKVHrIMmqnS0ViwRaZWhNLaGoBaMhmwd5YGhaW4R90jYmBMKGPgh9lkBIk0IRFjWxrZjSjTRiIa0xhlBot51VSdZdU01ide2anZDGpHmikm8f3COM4+7O7L1nZ/zefb9gmHvO3D/fw299e+fsPWyqCklSP7+w3QNIkqZjwCWpKQMuSU0ZcElqyoBLUlMLW/liF154YS0tLW3lS0pSewcPHvxhVS2u37+lAV9aWmJlZWUrX1KS2kvy3yfa7ykUSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1tWHAk9yV5HiSQ2v2XZDkwSRPDt/PP7NjSpLW28w78C8CN6zbtxd4qKouAx4atiVJW2jDgFfVN4Efrdu9G7h7uH038P5xx5IkbWTaKzEvqqpjw+3ngYtOdscke4A9AJdeeumULwdLe/9p6sdK0nZ6+lM3nZHnnfkvMWvyT/qc9J/1qap9VbVcVcuLi6+5lF+SNKVpA/6DJG8HGL4fH28kSdJmTBvw+4Fbhtu3AF8ZZxxJ0mZt5mOE9wL/Blye5GiSW4FPAb+X5Eng+mFbkrSFNvxLzKr64El+dN3Is0iSToNXYkpSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJamqmgCf5aJLHkxxKcm+SN481mCTp1KYOeJKdwIeB5ap6J3AOcPNYg0mSTm3WUygLwFuSLAA7gP+ZfSRJ0mZMHfCqeg74DPAMcAx4oar+Zf39kuxJspJkZXV1dfpJJUmvMssplPOB3cAu4B3AuUk+tP5+VbWvqparanlxcXH6SSVJrzLLKZTrge9X1WpVvQTcB/z2OGNJkjYyS8CfAa5OsiNJgOuAI+OMJUnayCznwA8A+4FHgG8Pz7VvpLkkSRtYmOXBVfVJ4JMjzSJJOg1eiSlJTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqamZAp7kvCT7kzyR5EiSd401mCTp1BZmfPznga9W1QeSvBHYMcJMkqRNmDrgSd4GvBv4I4CqehF4cZyxJEkbmeUUyi5gFfhCkkeT3JHk3JHmkiRtYJaALwBXAbdX1ZXAz4C96++UZE+SlSQrq6urM7ycJGmtWQJ+FDhaVQeG7f1Mgv4qVbWvqparanlxcXGGl5MkrTV1wKvqeeDZJJcPu64DDo8ylSRpQ7N+CuXPgHuGT6B8D/jj2UeSJG3GTAGvqseA5XFGkSSdDq/ElKSmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKZmDniSc5I8muSBMQaSJG3OGO/AbwOOjPA8kqTTMFPAk1wM3ATcMc44kqTNmvUd+OeAjwM/P9kdkuxJspJkZXV1dcaXkyS9YuqAJ3kvcLyqDp7qflW1r6qWq2p5cXFx2peTJK0zyzvwa4D3JXka+BJwbZK/G2UqSdKGpg54VX2iqi6uqiXgZuDrVfWh0SaTJJ2SnwOXpKYWxniSqvoG8I0xnkuStDm+A5ekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1NTUAU9ySZKHkxxO8niS28YcTJJ0agszPPZl4GNV9UiSXwQOJnmwqg6PNJsk6RSmfgdeVceq6pHh9k+BI8DOsQaTJJ3aKOfAkywBVwIHTvCzPUlWkqysrq6O8XKSJEYIeJK3Al8GPlJVP1n/86raV1XLVbW8uLg468tJkgYzBTzJG5jE+56qum+ckSRJmzHLp1AC3AkcqarPjjeSJGkzZnkHfg3wB8C1SR4bvm4caS5J0gam/hhhVf0rkBFnkSSdBq/ElKSmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKZmCniSG5J8J8lTSfaONZQkaWNTBzzJOcBfA+8BrgA+mOSKsQaTJJ3aLO/AfxN4qqq+V1UvAl8Cdo8zliRpIwszPHYn8Oya7aPAb62/U5I9wJ5h8/+SfGfK17sQ+OGUj+3obDres+lYweOdZyc81nx65uf95RPtnCXgm1JV+4B9sz5PkpWqWh5hpBbOpuM9m44VPN55ttXHOssplOeAS9ZsXzzskyRtgVkC/p/AZUl2JXkjcDNw/zhjSZI2MvUplKp6OcmfAv8MnAPcVVWPjzbZa818GqaZs+l4z6ZjBY93nm3psaaqtvL1JEkj8UpMSWrKgEtSUy0CPs+X7Ce5JMnDSQ4neTzJbcP+C5I8mOTJ4fv52z3rmJKck+TRJA8M27uSHBjW+O+HvxifC0nOS7I/yRNJjiR517yub5KPDn+ODyW5N8mb52ltk9yV5HiSQ2v2nXAtM/FXw3F/K8lVY8/zug/4WXDJ/svAx6rqCuBq4E+G49sLPFRVlwEPDdvz5DbgyJrtTwN/WVW/CvwvcOu2THVmfB74alX9GvDrTI577tY3yU7gw8ByVb2TyYcbbma+1vaLwA3r9p1sLd8DXDZ87QFuH3uY133AmfNL9qvqWFU9Mtz+KZP/uHcyOca7h7vdDbx/WwY8A5JcDNwE3DFsB7gW2D/cZW6ON8nbgHcDdwJU1YtV9WPmd30XgLckWQB2AMeYo7Wtqm8CP1q3+2RruRv4m5r4d+C8JG8fc54OAT/RJfs7t2mWMyrJEnAlcAC4qKqODT96Hrhou+Y6Az4HfBz4+bD9S8CPq+rlYXue1ngXsAp8YThldEeSc5nD9a2q54DPAM8wCfcLwEHmd21fcbK1POPt6hDws0KStwJfBj5SVT9Z+7OafNZzLj7vmeS9wPGqOrjds2yRBeAq4PaquhL4GetOl8zL+g7nfncz+Z/WO4Bzee3phrm21WvZIeBzf8l+kjcwifc9VXXfsPsHr/y6NXw/vl3zjewa4H1JnmZyOuxaJueIzxt+7Yb5WuOjwNGqOjBs72cS9Hlc3+uB71fValW9BNzHZL3ndW1fcbK1POPt6hDwub5kfzj/eydwpKo+u+ZH9wO3DLdvAb6y1bOdCVX1iaq6uKqWmKzl16vq94GHgQ8Md5un430eeDbJ5cOu64DDzOf6PgNcnWTH8Of6lWOdy7Vd42RreT/wh8OnUa4GXlhzqmUcVfW6/wJuBP4L+C7w59s9z8jH9jtMfuX6FvDY8HUjk/PCDwFPAl8DLtjuWc/Asf8u8MBw+1eA/wCeAv4BeNN2zzficf4GsDKs8T8C58/r+gJ/ATwBHAL+FnjTPK0tcC+T8/svMfnt6taTrSUQJp+g+y7wbSafzhl1Hi+ll6SmOpxCkSSdgAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JT/w/KLFzDiS2FdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_cross_valid, bins=[x for x in range(0, 103)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-stake",
   "metadata": {},
   "source": [
    "Looking at an image from the normalised training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arabic-white",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23490429820>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "geographic-platform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6149, 1020, 1020)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test), len(x_cross_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-allocation",
   "metadata": {},
   "source": [
    "## Building the first model\n",
    "\n",
    "We now have the data that our model will be training on, so we can proceed ahead to build a quick and a dirty model on which we will be working on throughout this notebook.\n",
    "\n",
    "1. For the first model, let us take 3 convulation layers, each followed by a max pooling layer, with a fully connected layer of neurons at the end of the convulation structure.\n",
    "2. For all the layers, we will be using the `relu` activation function and for the output layer, we will be using the `softmax` activation function.\n",
    "3. We will also be using the `same` padding to keep the dimensions of the image same throughout the convulation layers, and to also include the pixels at edge in more convulation operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "collective-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_model = Sequential([\n",
    "    # a convulation layer with 8 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 8 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 8 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # flattening the obtained array for ANN\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # a dense neural network layer with 256 neurons and relu activation\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    \n",
    "    # a dense output layer with 102 neurons (for 102 classes) and softmax activation\n",
    "    layers.Dense(102, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-representative",
   "metadata": {},
   "source": [
    "Let us compile our dirty model with `adam` optimizer, `SparseCategoricalCrossentropy` loss function (as our labels are not one hot encoded) and \"accuracy\" as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "geographic-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-marshall",
   "metadata": {},
   "source": [
    "Now let us try to fit our training data and let us run it for 100 epochs with a batch size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "asian-insulin",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 7s 17ms/step - loss: 4.4231 - accuracy: 0.0481\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.9253 - accuracy: 0.1078\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.3245 - accuracy: 0.1969\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.8715 - accuracy: 0.2721\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.5499 - accuracy: 0.3518\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.3037 - accuracy: 0.4032\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.0898 - accuracy: 0.4490\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.8846 - accuracy: 0.4923\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.7378 - accuracy: 0.5311\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.5567 - accuracy: 0.5702\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.3923 - accuracy: 0.6146\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.2253 - accuracy: 0.6627\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 1.0955 - accuracy: 0.6926\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.9934 - accuracy: 0.7172\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.8691 - accuracy: 0.7526\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.7642 - accuracy: 0.7809\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.6211 - accuracy: 0.8226\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.5473 - accuracy: 0.8427\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4407 - accuracy: 0.8805\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3835 - accuracy: 0.8974\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3137 - accuracy: 0.9143\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.2345 - accuracy: 0.9462\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1714 - accuracy: 0.9655\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1981 - accuracy: 0.9517\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1498 - accuracy: 0.9658\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1199 - accuracy: 0.9756\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.1027 - accuracy: 0.9782\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0681 - accuracy: 0.9914\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0518 - accuracy: 0.9948\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0368 - accuracy: 0.9964\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0200 - accuracy: 0.9997\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0128 - accuracy: 0.9998\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0113 - accuracy: 0.9995\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0093 - accuracy: 0.9998\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0105 - accuracy: 0.9997\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0079 - accuracy: 0.9998\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0106 - accuracy: 0.9997\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0218 - accuracy: 0.9972\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0109 - accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0126 - accuracy: 0.9990\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0093 - accuracy: 0.9997\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0113 - accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0176 - accuracy: 0.9982\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0450 - accuracy: 0.9904\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.4829 - accuracy: 0.8544\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3548 - accuracy: 0.8839\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1544 - accuracy: 0.9502\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0555 - accuracy: 0.9867\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0329 - accuracy: 0.9932\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0124 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0050 - accuracy: 0.9998\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0053 - accuracy: 0.9997\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0036 - accuracy: 0.9998\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0034 - accuracy: 0.9998\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0039 - accuracy: 0.9998\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0034 - accuracy: 0.9998\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0038 - accuracy: 0.9998 0s - loss: 0.0024 \n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0034 - accuracy: 0.9998\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0041 - accuracy: 0.9997\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0045 - accuracy: 0.9997\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0051 - accuracy: 0.9997\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0034 - accuracy: 0.9998\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0029 - accuracy: 0.9997\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0044 - accuracy: 0.9997 0s - loss: 0.0028 - accu\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0071 - accuracy: 0.9995\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0047 - accuracy: 0.9997\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0041 - accuracy: 0.9997\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0040 - accuracy: 0.9998\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0047 - accuracy: 0.9997\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.0044 - accuracy: 0.9997\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0047 - accuracy: 0.9997\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0045 - accuracy: 0.9997\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0042 - accuracy: 0.9997\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.0044 - accuracy: 0.9997\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0045 - accuracy: 0.9997\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0058 - accuracy: 0.9992\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.6563 - accuracy: 0.8151\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.3896 - accuracy: 0.8766\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1174 - accuracy: 0.9654\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0672 - accuracy: 0.9811\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0218 - accuracy: 0.9959\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0081 - accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0043 - accuracy: 0.9997\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0030 - accuracy: 0.9998\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0025 - accuracy: 0.9998\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0036 - accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0024 - accuracy: 0.9998\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0045 - accuracy: 0.9998\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0035 - accuracy: 0.9997\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0029 - accuracy: 0.9997\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0025 - accuracy: 0.9998\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 0.0023 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2350793f400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_model.fit(x_train, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-certificate",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "Our model reaches 99% accuracy very quick which looks very promising for the training data, but we cannot give a judgement without evaulating it on our cross-validation data. Let us now evaluate our dirty model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "covered-serve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 6ms/step - loss: 6.7689 - accuracy: 0.3490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.768937110900879, 0.3490196168422699]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_model.evaluate(x_cross_valid, y_cross_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-professional",
   "metadata": {},
   "source": [
    "The accuracy on the cross-validation data comes out to be 34% which is not at all good. This means that we are overfitting our training data. Some of the things that we can do to improve this overfitting our -\n",
    "\n",
    "1. Simplifying our network architecture.\n",
    "2. Using regularization in the form of drop-outs\n",
    "3. Using data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-comedy",
   "metadata": {},
   "source": [
    "## A better approach\n",
    "\n",
    "Now that we know that our model is working and is working good on the test data but not on the cross-validation data, let us build another model with a few drop out layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "supposed-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_model = Sequential([\n",
    "    # a convulation layer with 8 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 16 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 32 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # a dense neural network layer with 64 neurons and relu activation, followed by a dropout layer\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # a dense neural network layer with 128 neurons and relu activation, followed by a dropout layer    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    layers.Dense(102, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-grocery",
   "metadata": {},
   "source": [
    "compiling the model with same configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "facial-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "posted-solid",
   "metadata": {},
   "source": [
    "Fitting the training dataset on our model and running it for 100 epochs with a batch size of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accessory-rental",
   "metadata": {
    "scrolled": false,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 2s 17ms/step - loss: 4.3415 - accuracy: 0.0527\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.8107 - accuracy: 0.1093\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.4087 - accuracy: 0.1647\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.1157 - accuracy: 0.2213\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.8614 - accuracy: 0.2703\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.6699 - accuracy: 0.3080\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.4821 - accuracy: 0.3570\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.3448 - accuracy: 0.3819\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.1956 - accuracy: 0.4114\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.0622 - accuracy: 0.4331\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.9511 - accuracy: 0.4645\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.8338 - accuracy: 0.4863\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.6900 - accuracy: 0.5217\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.5679 - accuracy: 0.5529\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.4937 - accuracy: 0.5764\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.3921 - accuracy: 0.6012\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.2860 - accuracy: 0.6295\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.1724 - accuracy: 0.6560\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.0900 - accuracy: 0.6723\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 1.0263 - accuracy: 0.6939\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.9472 - accuracy: 0.7167\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.9082 - accuracy: 0.7253\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.8158 - accuracy: 0.7557\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.7244 - accuracy: 0.7826\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.6815 - accuracy: 0.7920\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.6773 - accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.6149 - accuracy: 0.8099\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.5469 - accuracy: 0.8262\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.5087 - accuracy: 0.8409\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4961 - accuracy: 0.8465\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4467 - accuracy: 0.8574\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.4116 - accuracy: 0.8662\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3709 - accuracy: 0.8797\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3787 - accuracy: 0.8784\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3590 - accuracy: 0.8876\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.3440 - accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3293 - accuracy: 0.8951\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.3173 - accuracy: 0.8995\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2877 - accuracy: 0.9093\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2677 - accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2457 - accuracy: 0.9218\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2565 - accuracy: 0.9143\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2620 - accuracy: 0.9154\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2603 - accuracy: 0.9125\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2111 - accuracy: 0.9325\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2296 - accuracy: 0.9250\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2290 - accuracy: 0.9268\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2319 - accuracy: 0.9218\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.2018 - accuracy: 0.9358\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2065 - accuracy: 0.9330\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1993 - accuracy: 0.9341\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1847 - accuracy: 0.9374\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2032 - accuracy: 0.9376\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.2005 - accuracy: 0.9384\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1632 - accuracy: 0.9478\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1679 - accuracy: 0.9471\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1848 - accuracy: 0.9392\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1590 - accuracy: 0.9476\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1497 - accuracy: 0.9517\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1626 - accuracy: 0.9478\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1889 - accuracy: 0.9382\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1618 - accuracy: 0.9475\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1652 - accuracy: 0.9475\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1491 - accuracy: 0.9528\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1419 - accuracy: 0.9541\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1244 - accuracy: 0.9595\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1478 - accuracy: 0.9530\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1220 - accuracy: 0.9623\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1337 - accuracy: 0.9590\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1184 - accuracy: 0.9615\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1559 - accuracy: 0.9486\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1457 - accuracy: 0.9499\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1385 - accuracy: 0.9540\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1240 - accuracy: 0.9608\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1258 - accuracy: 0.9566\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1301 - accuracy: 0.9572\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1368 - accuracy: 0.9546\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1319 - accuracy: 0.9569\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1150 - accuracy: 0.9634\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1048 - accuracy: 0.9652\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1076 - accuracy: 0.9655\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1237 - accuracy: 0.9587\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 0.1253 - accuracy: 0.9608\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1181 - accuracy: 0.9603\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1329 - accuracy: 0.9577\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1227 - accuracy: 0.9606\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1107 - accuracy: 0.9629\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1035 - accuracy: 0.9667\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1053 - accuracy: 0.9657\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0897 - accuracy: 0.9701\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1177 - accuracy: 0.9639\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1212 - accuracy: 0.9590\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1335 - accuracy: 0.9564\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1099 - accuracy: 0.9647\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1025 - accuracy: 0.9667\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1079 - accuracy: 0.9655\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0843 - accuracy: 0.9732\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.0907 - accuracy: 0.9702\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1035 - accuracy: 0.9665\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 0.1088 - accuracy: 0.9623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2350a238a60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_model.fit(x_train, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-affiliation",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-project",
   "metadata": {},
   "source": [
    "We can see that the evaluation accuracy is still not good but is greater than the one we got in our dirty model. I tried a lot of combinations of hyperparameters, different architectures, different dropouts, different epochs but I still couldn't get accuracy > 50% after adding dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "applicable-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 5ms/step - loss: 4.4875 - accuracy: 0.4137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.487522125244141, 0.41372549533843994]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better_model.evaluate(x_cross_valid, y_cross_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-stuff",
   "metadata": {},
   "source": [
    "Now let us try to use data augmentation, which will take care of different orientations, contrasts and zoooming properties of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-discrimination",
   "metadata": {},
   "source": [
    "## An even better model\n",
    "\n",
    "Now that we know that our model is still overfitting the data, we try to augment the available data to prepare the model for augmented data coming through the cross-validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stainless-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = Sequential(\n",
    "  [\n",
    "    # adding random contrast, rotation and zoom\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomRotation(0.4),\n",
    "    layers.RandomZoom(0.2),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-humidity",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "injured-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    # passing the data augmentation layer first\n",
    "    data_augmentation,\n",
    "    # a convulation layer with 16 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 32 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # a convulation layer with 64 3X3 filters, relu activation and same padding followed by a max pooling layer\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    # flattening the obtained array for ANN\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # a dense neural network layer with 512 neurons and relu activation\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # a dense neural network layer with 512 neurons and relu activation\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # a dense neural network layer with 512 neurons and relu activation\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # a dense output layer with 102 neurons (for 102 classes) and softmax activation\n",
    "    layers.Dense(102, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "boxed-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "optional-boards",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 6s 23ms/step - loss: 4.2461 - accuracy: 0.0542\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.6861 - accuracy: 0.1075\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.3770 - accuracy: 0.1538\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 3.1520 - accuracy: 0.1909\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.9785 - accuracy: 0.2207\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.8440 - accuracy: 0.2472\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.7283 - accuracy: 0.2701\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.6668 - accuracy: 0.2874\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.5661 - accuracy: 0.3069\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.4514 - accuracy: 0.3318\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.3890 - accuracy: 0.3531\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.2871 - accuracy: 0.3659\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.2283 - accuracy: 0.3864\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.1352 - accuracy: 0.4028\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.0868 - accuracy: 0.4181\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 2.0222 - accuracy: 0.4404\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.9084 - accuracy: 0.4706\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8711 - accuracy: 0.4736\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.8339 - accuracy: 0.4887\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7763 - accuracy: 0.4944\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.7162 - accuracy: 0.5128\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6838 - accuracy: 0.5162\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.6140 - accuracy: 0.5367\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5965 - accuracy: 0.5398\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5492 - accuracy: 0.5487\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.5129 - accuracy: 0.5593\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4635 - accuracy: 0.5746\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.4533 - accuracy: 0.5764\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.4001 - accuracy: 0.5890\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.3638 - accuracy: 0.5947\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 1.3520 - accuracy: 0.5972\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2997 - accuracy: 0.6035\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2416 - accuracy: 0.6287\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.2588 - accuracy: 0.6250\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.2093 - accuracy: 0.6347\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 1.1618 - accuracy: 0.6539\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 1.1277 - accuracy: 0.6580\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 1.1281 - accuracy: 0.6575\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1087 - accuracy: 0.6588\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.1171 - accuracy: 0.6650\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 1.0417 - accuracy: 0.6827\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0194 - accuracy: 0.6952\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 1.0270 - accuracy: 0.6824\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 1.0398 - accuracy: 0.6865\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9844 - accuracy: 0.6926\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9823 - accuracy: 0.6957\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9778 - accuracy: 0.6946\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.9656 - accuracy: 0.7022\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.9333 - accuracy: 0.7141\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8922 - accuracy: 0.7256\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8502 - accuracy: 0.7382\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8757 - accuracy: 0.7206\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8713 - accuracy: 0.7268\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8458 - accuracy: 0.7351\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8411 - accuracy: 0.7361\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8324 - accuracy: 0.7354\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.8302 - accuracy: 0.7362\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7686 - accuracy: 0.7543\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7671 - accuracy: 0.7510\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.7934 - accuracy: 0.7465\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7420 - accuracy: 0.7696\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7824 - accuracy: 0.7552\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7293 - accuracy: 0.7648\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7542 - accuracy: 0.7648\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7280 - accuracy: 0.7710\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7054 - accuracy: 0.7752 0s - loss: 0.7009 - accuracy: \n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.7103 - accuracy: 0.7738\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.7087 - accuracy: 0.7777\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6793 - accuracy: 0.7850\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6650 - accuracy: 0.7845\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6311 - accuracy: 0.8009\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.6420 - accuracy: 0.7967\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.6768 - accuracy: 0.7873\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 0.6324 - accuracy: 0.7961\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6381 - accuracy: 0.7956\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6142 - accuracy: 0.8057\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6036 - accuracy: 0.8131\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6369 - accuracy: 0.7956\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6224 - accuracy: 0.8026\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5870 - accuracy: 0.8187\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 19ms/step - loss: 0.6090 - accuracy: 0.8039\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5777 - accuracy: 0.8070\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5934 - accuracy: 0.8097\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.6057 - accuracy: 0.8061\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5634 - accuracy: 0.8167\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5306 - accuracy: 0.8283\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5353 - accuracy: 0.8239\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5413 - accuracy: 0.8297\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5234 - accuracy: 0.8310\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5419 - accuracy: 0.8224\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5376 - accuracy: 0.8268\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5321 - accuracy: 0.8312\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5338 - accuracy: 0.8284\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5449 - accuracy: 0.8252\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5258 - accuracy: 0.8320\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5006 - accuracy: 0.8336\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 20ms/step - loss: 0.5147 - accuracy: 0.8383\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5019 - accuracy: 0.8375\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.4950 - accuracy: 0.8424\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 19ms/step - loss: 0.5006 - accuracy: 0.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2350cb9f6d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sound-solution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 2.7316 - accuracy: 0.5422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.731625556945801, 0.5421568751335144]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_cross_valid, y_cross_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-romance",
   "metadata": {},
   "source": [
    "I tried a lot of configurations (more dropouts, simpler architecture, more/less filters, more augmentation etc.) but I couldn't get the accuracy > 60%. This was the first time that I trained a convulation neural network, and honestly I read about pooling and data augmentation just a day before writing this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-interstate",
   "metadata": {},
   "source": [
    "## Evaluationg on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quarterly-large",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 2.9463 - accuracy: 0.5069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9462838172912598, 0.5068627595901489]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-notion",
   "metadata": {},
   "source": [
    "## Some predictions\n",
    "\n",
    "Let us finally predict some flowers because everyone loves predicting stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "unauthorized-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test[40:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aging-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [np.argmax(x) for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "asian-person",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([69, 12, 88, 4, 75, 87, 14, 21, 81, 96],\n",
       " array([52, 12,  4,  4, 75, 79, 14, 21,  0, 35]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, y_test[40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-conclusion",
   "metadata": {},
   "source": [
    "## Some final words\n",
    "\n",
    "I actually had fun while building this notebook, and these 2 days were full of learning. I had never coded out a CNN before which now I confidently can (I knew ANNs and have worked with smaller and basic images like the MNIST dataset with ANNs). Finally, I knew a lot of optimization techniques for ANNs but I knew nothing about CNNs, and learning, and applying these techniques was very satisfying.\n",
    "\n",
    "Thanks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-hours",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
